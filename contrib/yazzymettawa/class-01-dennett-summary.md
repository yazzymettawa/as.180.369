PROMPT: "Read this article and my summary. What are major points I missed?," the summary and article 
OUTPUT: To consider Definition and Scope of "Counterfeit People", Philosophical and Historical Context, Evolutionary Risk, Watermarking as a Solution, Ethical and Legal Implications, Potential for a New Form of Propaganda with summaries for each. 

REWRITE #2: 
In the piece “The Problem With Counterfeit People” Daniel C. Dennett argues that “we must outlaw both the creation of counterfeit people and the ‘passing along’ of counterfeit people. The penalties for either offense should be extremely severe, given that civilization itself is at risk.” Dennett’s piece lacks in a convincing argument as it employs new language not well defined language as a scare tactic and proposes a solution to the very real problems Artificial Intelligence poses that is contradictory to Dennett’s stated philosophy and governmental distrust. 

Dennett reinforces his argument through providing historical context on the creation of AI. From the beginning, with Alan Turning’s Imitation Game, AI has successfully tricked people into interacting with the technology as though it is sentient or human like. To further this notion that people confuse AI with human behavior Dennett argues that the rate of evolution in the technology lends to an increase in the amount of “counterfeit people.” 

The primary flaw in these arguments is that the term counterfeit people is not clearly defined, however deep fakes, and sources like OpenAI, are both provided as examples in the article of “counterfeit people.” As these are two very different ends of the spectrum of what constitutes AI, and without a clear definition it can be assumed that by “counterfeit people” is referring to any technology that attempts to mimic the behaviors of humans. Without a clear definition this could seemingly apply to all AI, in which case I would argue the term serves no function other than to work as a scare tactic and undermines the authors argument. People are simply not interacting with OpenAI completely unaware it is non-human and thus the type of Artificial Intelligence the author warns of are simply not the ones of grave danger that he warns of. Fundamentally the article aims to instill fear in the reader over the future of Artificial Intelligence through using this new language of “counterfeit people.” 

The article also provides quite random sources, a philosopher and historian who writes for the Economist is cited a few times but never says anything of substance outside of reiterating a similar fearful tone as the author, which again undermines his argument and lends the piece to be one of fear mongering rather than genuine critique. 

Some decent points are made, such as when it explains the endless issue of creating programs that learn to identify AI only to lead to AI that takes this information and learns to get around being detected as AI. The issues in being unable to detect AI for the future of copyright law and literary and artistic credit, or really any medium where idea generation is valued and credit being provided is important. 

The main solution in the eyes of the author is to have capital punishment be the crime for creating "Counterfeit People," but he is generally against this idea. Additionally this suggestion would require legislation in order to end the usage of AI, however the author has a distrust of authority as he believes AI will be used as a form of propaganda to convince individuals into agreeing with certain policies. Therefore the suggestion of government regulation would be inherently against the author's stated beliefs.  
